{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FbiPsNSy5xGBGW8V4PEm3sUWNnmaOlDr",
      "authorship_tag": "ABX9TyMwB27yWSsgQMpM/rUabohC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnsonsingam/final-exam/blob/main/final_exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDfP0TQpkXgb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Model builder function\n",
        "def build_model(optimizer='adam'):\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 3. Manual hyperparameter search\n",
        "optimizers = ['adam', 'sgd']\n",
        "batch_sizes = [64, 128]\n",
        "best_acc = 0\n",
        "best_params = {}\n",
        "for opt in optimizers:\n",
        "    for bs in batch_sizes:\n",
        "        model = build_model(optimizer=opt)\n",
        "        history = model.fit(x_train, y_train_cat, epochs=3, batch_size=bs, verbose=0, validation_data=(x_test, y_test_cat))\n",
        "        acc = history.history['val_accuracy'][-1]\n",
        "        print(f\"Optimizer: {opt}, Batch size: {bs}, Val Acc: {acc:.4f}\")\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_params = {'optimizer': opt, 'batch_size': bs}\n",
        "\n",
        "print(\"Best params:\", best_params)\n",
        "\n",
        "# 4. Train final model with best hyperparameters and ReduceLROnPlateau\n",
        "final_model = build_model(optimizer=best_params['optimizer'])\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5)\n",
        "history = final_model.fit(\n",
        "    x_train, y_train_cat,\n",
        "    epochs=10,\n",
        "    batch_size=best_params['batch_size'],\n",
        "    validation_data=(x_test, y_test_cat),\n",
        "    callbacks=[reduce_lr]\n",
        ")\n",
        "\n",
        "# 5. Confusion matrix\n",
        "y_pred = np.argmax(final_model.predict(x_test), axis=1)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 6. Training/testing loss and accuracy plots\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Test Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Test Acc')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# 7. ROC curve for one class (e.g., digit 0)\n",
        "y_score = final_model.predict(x_test)\n",
        "fpr, tpr, _ = roc_curve(y_test_cat[:, 0], y_score[:, 0])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Digit 0')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nsxXwiZuqV8y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}